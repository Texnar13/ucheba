{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4b22ab2-322c-421f-880e-0ba00572c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# пути к Java и Spark\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/ubuntu/_practice/spark-3.5.4-bin-hadoop3\"\n",
    "os.environ[\"PATH\"] += os.pathsep + os.path.join(os.environ[\"SPARK_HOME\"], \"bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62cb8516-cbd3-42f8-93fd-afdf4752f432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/08 17:46:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkContext запущен: <SparkContext master=local[*] appName=PlacesDistance>\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "print(pyspark.__version__)\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\").setAppName(\"PlacesDistance Marchuk\"))\n",
    "\n",
    "print(\"SparkContext запущен:\", sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d21f89ab-8b8a-43ac-b13c-a742f1c890df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import csv\n",
    "\n",
    "# Формула гаверсинуса\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Радиус Земли в километрах\n",
    "    dlat = math.radians(lat2 - lat1)\n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "# Функция для парсинга CSV \n",
    "def parse_csv_line(line):\n",
    "    reader = csv.reader([line])\n",
    "    return next(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11825d98-daee-4e5e-941a-751ad24acf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# как скопировать файл в hdfs\n",
    "#hdfs dfs -mkdir /dataset\n",
    "#hdfs dfs -put /home/ubuntu/_practice/places.csv /dataset/places.csv\n",
    "\n",
    "# Загрузим данные places.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2b487f2-c52f-4c64-8354-53cd2e9d52ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "file_path = \"/dataset/places.csv\" \n",
    "data = sc.textFile(file_path)\n",
    "\n",
    "# Заголовки и данные\n",
    "header = data.first()\n",
    "rows = data.filter(lambda line: line != header).map(parse_csv_line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48cf7b53-975c-4eab-a56d-dfdf403ecb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Рассчитаем расстояние от заданной точки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccd0b3ec-3e2a-4679-9033-844e173bbb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первые 10 расстояний от заданной точки:\n",
      "Мареа: 1.06 км\n",
      "Стейк Хаус «Бизон»: 1.06 км\n",
      "ЛяМур: 1.07 км\n",
      "БИБЛИОТЕКА Shisha Lounge: 1.07 км\n",
      "Му-Му: 1.07 км\n",
      "Unlock cafe: 1.07 км\n",
      "Папа Джонс: 1.07 км\n",
      "Jimmy Poy: 1.07 км\n",
      "Шоколадница: 1.07 км\n",
      "Настоишная: 1.07 км\n"
     ]
    }
   ],
   "source": [
    "# Координаты точки\n",
    "origin_lat, origin_lng = 55.751244, 37.618423\n",
    "\n",
    "# Расчет расстояний\n",
    "distances_from_origin = rows.map(lambda row: (row[1], haversine(origin_lat, origin_lng, float(row[13]), float(row[12]))))\n",
    "top_10_nearby = distances_from_origin.takeOrdered(10, key=lambda x: x[1])\n",
    "\n",
    "print(\"Первые 10 расстояний от заданной точки:\")\n",
    "for place, distance in top_10_nearby:\n",
    "    print(f\"{place}: {distance:.2f} км\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7c8e968-b256-4108-b65b-fe00508cdb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Рассчитаем расстояние между всеми заведениями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc7280d2-86a4-40cd-83cd-3b5cbf35f631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первые 10 расстояний между заведениями:\n",
      "МУ-МУ - КОМБИНАТ ПИТАНИЯ МГТУ ИМ.Н.Э.БАУМАНА: 0.68 км\n",
      "МУ-МУ - Дом 12: 1.48 км\n",
      "МУ-МУ - Чито-Ра: 1.45 км\n",
      "МУ-МУ - Бар- буфет «Николай»: 1.58 км\n",
      "МУ-МУ - Флорентини: 1.52 км\n",
      "МУ-МУ - Beer Gik: 2.98 км\n",
      "МУ-МУ - Погребок: 2.98 км\n",
      "МУ-МУ - Пробка Гриль: 2.89 км\n",
      "МУ-МУ - TEMPO DI PASTA: 2.90 км\n",
      "МУ-МУ - Хлеб насущный: 2.90 км\n"
     ]
    }
   ],
   "source": [
    "# Создаем пары заведений и рассчитываем расстояния\n",
    "pairs = rows.cartesian(rows).filter(lambda x: x[0][0] != x[1][0])  # Исключаем одинаковые объекты\n",
    "distances_between_places = pairs.map(lambda x: ((x[0][1], x[1][1]), \n",
    "                                                haversine(float(x[0][13]), float(x[0][12]), float(x[1][13]), float(x[1][12]))))\n",
    "\n",
    "print(\"Первые 10 расстояний между заведениями:\")\n",
    "for (place1, place2), distance in distances_between_places.take(10):\n",
    "    print(f\"{place1} - {place2}: {distance:.2f} км\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87828f1f-6abe-43ce-81af-d1d2fe1e7fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Найдем топ-10 самых близких и самых отдаленных заведений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d5fc140-32d8-4f95-9e14-02b8de13a8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 наиболее близких заведений:\n",
      "Beer Gik - Погребок: 0.00 км\n",
      "Beer Gik - Kozlovna: 0.00 км\n",
      "Beer Gik - Па-Паэлья: 0.00 км\n",
      "Погребок - Beer Gik: 0.00 км\n",
      "TEMPO DI PASTA - Хлеб насущный: 0.00 км\n",
      "Хлеб насущный - TEMPO DI PASTA: 0.00 км\n",
      "Погребок - Kozlovna: 0.00 км\n",
      "Погребок - Па-Паэлья: 0.00 км\n",
      "Глав Пив Маг - Beermood: 0.00 км\n",
      "Beermood - Глав Пив Маг: 0.00 км\n",
      "\n",
      "10 наиболее отдаленных заведений:\n",
      "МНИТИ - Calabash Club: 5.46 км\n",
      "МНИТИ - Залечь на дно: 5.46 км\n",
      "МНИТИ - Политех: 5.46 км\n",
      "Calabash Club - МНИТИ: 5.46 км\n",
      "Залечь на дно - МНИТИ: 5.46 км\n",
      "Политех - МНИТИ: 5.46 км\n",
      "МНИТИ - Антикафе Checkpoint: 5.46 км\n",
      "Антикафе Checkpoint - МНИТИ: 5.46 км\n",
      "МНИТИ - Шоколадница: 5.40 км\n",
      "Шоколадница - МНИТИ: 5.40 км\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Сортируем по расстоянию\n",
    "top_10_closest = distances_between_places.takeOrdered(10, key=lambda x: x[1])\n",
    "top_10_farthest = distances_between_places.takeOrdered(10, key=lambda x: -x[1])\n",
    "\n",
    "print(\"10 наиболее близких заведений:\")\n",
    "for (place1, place2), distance in top_10_closest:\n",
    "    print(f\"{place1} - {place2}: {distance:.2f} км\")\n",
    "\n",
    "print(\"\\n10 наиболее отдаленных заведений:\")\n",
    "for (place1, place2), distance in top_10_farthest:\n",
    "    print(f\"{place1} - {place2}: {distance:.2f} км\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e254d957-d179-4730-9321-9555d2647946",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "=============== Задание 2 ===============\n",
    "\n",
    "\n",
    "   1. Рассчитайте средний рейтинг товаров из набора данных.\n",
    "   2. Сопоставьте полученные данные из предыдущего пункта с наименованием товаров.\n",
    "   3. Сформируйте RDD товаров с рейтингом меньшим 3. Выведите топ-10 товаров с наименьшим рейтингом.\n",
    "   4. Сохраните результат в постоянное хранилище.\n",
    "\n",
    "Замечание: для парсинга товаров используйте функцию eval.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ed65d3-5b8d-490a-97c6-8bef445f8567",
   "metadata": {},
   "source": [
    "1. расчёт среднего рейтинга товаров\n",
    "\n",
    "hdfs dfs -put /home/ubuntu/_practice/Electronics_5.json /dataset/Electronics_5.json\n",
    "hdfs dfs -put /home/ubuntu/_practice/meta_Electronics.json /dataset/meta_Electronics.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "087a07f2-4b50-4122-bc6b-ddd508f8d827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/08 17:50:55 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 товаров с рейтингом ниже 3:\n",
      "Название: ATI TV Wonder 200 PCI Video Card w/PVR Capabilities, Рейтинг: 1.0\n",
      "Название: StarTech HDMISPL1HH 1 feet Standard HDMI Cable - 1x HDMI (M) to 2x HDMI (F) (Discontinued by Manufacturer), Рейтинг: 1.0\n",
      "Название: GE 24746 Futura HDTV Ready Antenna, Рейтинг: 1.0\n",
      "Название: Agfa ePhoto SMILE 0.2MP Digital Camera, Рейтинг: 1.0\n",
      "Название: Dynex-DX-AP100 Adapter Mini DVI to Mini-DIN, Рейтинг: 1.0\n",
      "Название: RCA DRC8335 DVD Recorder &amp; VCR Combo With Built-In Tuner, Рейтинг: 1.0\n",
      "Название: Maxtor OneTouch 4 - 1 TB USB 2.0 Desktop External Hard Drive STM310005OTA3E1-RK, Рейтинг: 1.0\n",
      "Название: Zeikos 57-in-1 USB 2.0 Flash Memory Card Reader ZE-CR201, Рейтинг: 1.0\n",
      "Название: NEEWER&reg; Photographic Barn Door &amp; Honeycomb Grid &amp; Gel Set for Alienbees Alienbee Flash, Рейтинг: 1.0\n",
      "Название: NEW SYLVANIA HD1Z SDSDHCMMC 720P HARD DRIVE POCKET VIDEO DIGITAL CAMERACAMCORDER W4X DIGITAL ZOOM HDMI &amp; 2 LCD PEACOCK BLUE, Рейтинг: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg\n",
    "\n",
    "# Создаем сессию\n",
    "spark = SparkSession.builder.appName(\"Electronics Ratings Marchuk\").getOrCreate()\n",
    "\n",
    "# Загружаем данные\n",
    "reviews_path = \"/dataset/Electronics_5.json\"\n",
    "meta_path = \"/dataset/meta_Electronics.json\"\n",
    "\n",
    "reviews_df = spark.read.json(reviews_path)\n",
    "meta_df = spark.read.json(meta_path)\n",
    "\n",
    "# 1. Рассчитайте средний рейтинг товаров\n",
    "avg_ratings_df = reviews_df.groupBy(\"asin\").agg(avg(\"overall\").alias(\"average_rating\"))\n",
    "\n",
    "# 2. Сопоставьте с наименованием товаров\n",
    "product_ratings_df = avg_ratings_df.join(meta_df.select(\"asin\", \"title\"), on=\"asin\", how=\"inner\")\n",
    "\n",
    "# 3. Создайте RDD товаров с рейтингом < 3 и выведите топ-10\n",
    "low_rated_products_rdd = product_ratings_df.filter(col(\"average_rating\") < 3).rdd\n",
    "top_10_low_rated = low_rated_products_rdd.takeOrdered(10, key=lambda row: row[\"average_rating\"])\n",
    "\n",
    "# Выводим топ-10 товаров\n",
    "print(\"Top-10 товаров с рейтингом ниже 3:\")\n",
    "for product in top_10_low_rated:\n",
    "    print(f\"Название: {product['title']}, Рейтинг: {product['average_rating']}\")\n",
    "\n",
    "# 4. Сохраните результат в постоянное хранилище\n",
    "output_path = \"hdfs://localhost:9000/dataset/low_rated_products\"\n",
    "low_rated_products_rdd.saveAsTextFile(output_path)\n",
    "\n",
    "# Останавливаем Spark-сессию\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35173312-8c45-4115-b12f-28508058764f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "=============== Задание 3 ===============\n",
    "\n",
    "1. Вычислите косинусное сходство между рейтингами фильмов.\n",
    "2. Для фильма с movieId равным 589 сформируйте RDD со значениями сходства с остальными фильмами\n",
    "3. Добавьте наименования фильмов.\n",
    "4. Выведите топ-10 наиболее похожих фильмов.\n",
    "\n",
    "Пример расчета посредством SQL (без нормализации):\n",
    "SELECT r1.prodId, r2.prodId, SUM(r1.val * r2.val) AS sim\n",
    "FROM rating AS r1 JOIN rating AS r2 ON r1.userId = r2.userId\n",
    "WHERE r1.prodId < r2.prodId\n",
    "GROUP BY r1.prodId, r2.prodId"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f840adf6-ec30-46f5-9108-ddd11abb90b1",
   "metadata": {},
   "source": [
    "Загрузка данных\n",
    "\n",
    "hdfs dfs -put /home/ubuntu/_practice/movies.csv /dataset/movies.csv\n",
    "hdfs dfs -put /home/ubuntu/_practice/links.csv /dataset/links.csv\n",
    "hdfs dfs -put /home/ubuntu/_practice/ratings.csv /dataset/ratings.csv\n",
    "hdfs dfs -put /home/ubuntu/_practice/tags.csv /dataset/tags.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "988401a8-8682-4a92-8f54-5b84f1fc3cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, sum\n",
    "\n",
    "# Создаем Spark-сессию\n",
    "spark = SparkSession.builder.appName(\"Movies shojest Marchuk\").getOrCreate()\n",
    "\n",
    "# Загружаем данные\n",
    "ratings_path = \"/dataset/ratings.csv\"\n",
    "movies_path = \"/dataset/movies.csv\"\n",
    "\n",
    "ratings_df = spark.read.csv(ratings_path, header=True, inferSchema=True)\n",
    "movies_df = spark.read.csv(movies_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "645ca8dc-adcb-4d19-9f71-4f80f273e2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/08 18:25:44 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "25/01/08 18:25:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/08 18:25:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/08 18:25:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/08 18:25:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/08 18:25:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/08 18:25:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/08 18:25:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/08 18:25:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/08 18:25:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/08 18:25:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/08 18:25:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/08 18:25:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/08 18:25:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 112:>                                                        (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+------------------+------------------+------------------+\n",
      "|movieId|movieId|dot_product|norm_r1           |norm_r2           |cosine_similarity |\n",
      "+-------+-------+-----------+------------------+------------------+------------------+\n",
      "|1208   |2000   |561.5      |26.65520587052368 |21.857492994394395|0.9637566141949288|\n",
      "|1348   |2139   |70.0       |7.533259586659682 |9.433981132056603 |0.9849634244894794|\n",
      "|599    |1103   |82.5       |8.48528137423857  |10.161200716450788|0.956847375878929 |\n",
      "|599    |920    |65.0       |7.937253933193772 |8.888194417315589 |0.9213603870522182|\n",
      "|599    |3160   |99.0       |9.38083151964686  |11.090536506409418|0.9515712295346307|\n",
      "|1721   |6377   |992.25     |29.62262648719725 |34.92134018046845 |0.9591944178885445|\n",
      "|3896   |161582 |59.5       |7.365459931328117 |8.32165848854662  |0.970749567218328 |\n",
      "|4963   |7323   |206.5      |14.38749456993816 |14.84082207965583 |0.9671123399067233|\n",
      "|1259   |1895   |107.0      |11.01135777277262 |9.886859966642595 |0.9828438421679094|\n",
      "|1259   |2111   |80.0       |10.259142264341596|8.06225774829855  |0.9672132924431663|\n",
      "+-------+-------+-----------+------------------+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lit, sum, sqrt, pow, when\n",
    "\n",
    "# Создаем Spark-сессию\n",
    "spark = SparkSession.builder.appName(\"Movie Similarity Marchuk\").getOrCreate()\n",
    "\n",
    "# Загружаем данные\n",
    "ratings_path = \"/dataset/ratings.csv\"\n",
    "movies_path = \"/dataset/movies.csv\"\n",
    "\n",
    "ratings_df = spark.read.csv(ratings_path, header=True, inferSchema=True)\n",
    "movies_df = spark.read.csv(movies_path, header=True, inferSchema=True)\n",
    "\n",
    "# Удаляем дублирующие записи\n",
    "ratings_df = ratings_df.dropDuplicates([\"userId\", \"movieId\"])\n",
    "\n",
    "# Преобразуем данные в форматы удобные для расчетов\n",
    "ratings_aliased = ratings_df.alias(\"r1\").join(\n",
    "    ratings_df.alias(\"r2\"), on=\"userId\"\n",
    ").where(col(\"r1.movieId\") < col(\"r2.movieId\"))\n",
    "\n",
    "similarity_df = ratings_aliased.groupBy(\"r1.movieId\", \"r2.movieId\").agg(\n",
    "    sum(col(\"r1.rating\") * col(\"r2.rating\")).alias(\"dot_product\"),\n",
    "    sqrt(sum(pow(col(\"r1.rating\"), 2))).alias(\"norm_r1\"),\n",
    "    sqrt(sum(pow(col(\"r2.rating\"), 2))).alias(\"norm_r2\"),\n",
    ").withColumn(\n",
    "    \"cosine_similarity\",\n",
    "    col(\"dot_product\") / (col(\"norm_r1\") * col(\"norm_r2\"))\n",
    ")\n",
    "\n",
    "# Косинусное сходство\n",
    "similarity_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bbc623-c880-406f-8a4d-ffa1b3722ce4",
   "metadata": {},
   "source": [
    "2. Для фильма с movieId равным 589 сформируйте RDD со значениями сходства с остальными фильмами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd3c7987-48b0-4886-bafd-123c946521a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+\n",
      "|similar_movieId|cosine_similarity |\n",
      "+---------------+------------------+\n",
      "|4896           |0.9493927639264939|\n",
      "|1391           |0.9264611057456877|\n",
      "|54503          |0.9718665168836798|\n",
      "|43928          |0.8642944121755471|\n",
      "|5669           |0.9470464185036753|\n",
      "|2580           |0.9719296158512897|\n",
      "|12             |0.8575362261996874|\n",
      "|7839           |1.0               |\n",
      "|4808           |0.9959355660022436|\n",
      "|5875           |1.0               |\n",
      "+---------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# фильтруем сходство с фильмом 589\n",
    "movie_589_similarity = similarity_df.filter((col(\"r1.movieId\") == 589) | (col(\"r2.movieId\") == 589))\n",
    "\n",
    "# Упрощаем movieId (оставляем только сравниваемые фильмы)\n",
    "movie_589_similarity = movie_589_similarity.withColumn(\n",
    "    \"similar_movieId\",\n",
    "    when(col(\"r1.movieId\") != 589, col(\"r1.movieId\")).otherwise(col(\"r2.movieId\"))\n",
    ").select(\"similar_movieId\", \"cosine_similarity\")\n",
    "\n",
    "# Сходство с фильмом 589\n",
    "movie_589_similarity.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a611b8-ac13-4de9-8372-ca376fa606ed",
   "metadata": {},
   "source": [
    "3. Добавьте наименования фильмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92768d4d-7947-4d2d-a17f-3dd019b66e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------+------------------+\n",
      "|title                                                                                         |cosine_similarity |\n",
      "+----------------------------------------------------------------------------------------------+------------------+\n",
      "|Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)|0.9493927639264939|\n",
      "|Mars Attacks! (1996)                                                                          |0.9264611057456877|\n",
      "|Superbad (2007)                                                                               |0.9718665168836798|\n",
      "|Ultraviolet (2006)                                                                            |0.8642944121755471|\n",
      "|Bowling for Columbine (2002)                                                                  |0.9470464185036753|\n",
      "|Go (1999)                                                                                     |0.9719296158512897|\n",
      "|Dracula: Dead and Loving It (1995)                                                            |0.8575362261996874|\n",
      "|Love Crazy (1941)                                                                             |1.0               |\n",
      "|Vanishing, The (1993)                                                                         |0.9959355660022436|\n",
      "|Personal Velocity (2002)                                                                      |1.0               |\n",
      "+----------------------------------------------------------------------------------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# добавляем названия фильмов\n",
    "movie_589_similarity_with_titles = movie_589_similarity.join(\n",
    "    movies_df, movie_589_similarity[\"similar_movieId\"] == movies_df[\"movieId\"], \"inner\"\n",
    ").select(\"title\", \"cosine_similarity\")\n",
    "\n",
    "# Промежуточный вывод: Сходство с названиями\n",
    "movie_589_similarity_with_titles.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdbe6dc-17d4-428f-b839-15dc5e57478a",
   "metadata": {},
   "source": [
    "4. Выведите топ-10 наиболее похожих фильмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "debfd16b-bc58-48a1-ac48-9b82c948e5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------+------------------+\n",
      "|title                                               |cosine_similarity |\n",
      "+----------------------------------------------------+------------------+\n",
      "|Hoffa (1992)                                        |1.0000000000000002|\n",
      "|Coal Miner's Daughter (1980)                        |1.0000000000000002|\n",
      "|Rare Exports: A Christmas Tale (Rare Exports) (2010)|1.0000000000000002|\n",
      "|Man Who Fell to Earth, The (1976)                   |1.0000000000000002|\n",
      "|Red Corner (1997)                                   |1.0000000000000002|\n",
      "|Stunt Man, The (1980)                               |1.0000000000000002|\n",
      "|Death at a Funeral (2007)                           |1.0000000000000002|\n",
      "|Abandoned, The (2006)                               |1.0               |\n",
      "|Cranes Are Flying, The (Letyat zhuravli) (1957)     |1.0               |\n",
      "|Pyromaniac's Love Story, A (1995)                   |1.0               |\n",
      "+----------------------------------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_10_similar_movies = movie_589_similarity_with_titles.orderBy(\n",
    "    col(\"cosine_similarity\").desc()\n",
    ").limit(10)\n",
    "\n",
    "# Итоговый вывод\n",
    "top_10_similar_movies.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a162cb5-d1c5-4651-a73a-63d0275b6fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
