{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ce1c662-003d-4ed5-9038-57f28a622404",
   "metadata": {},
   "source": [
    "***Вариант***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab92a08-c98f-45be-a27b-a34e190d1086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Задача № 1:  1\n",
      "Задача № 2:  2\n"
     ]
    }
   ],
   "source": [
    "surname = \"марчук\" #Ваша фамилия\n",
    "\n",
    "alp = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя'\n",
    "w = [1, 42, 21, 21, 34,  6, 44, 26, 18, 44, 38, 26, 14, 43,  4, 49, 45,\n",
    "        7, 42, 29,  4,  9, 36, 34, 31, 29,  5, 30,  4, 19, 28, 25, 33]\n",
    "\n",
    "d = dict(zip(alp, w))\n",
    "variant =  sum([d[el] for el in surname.lower()]) % 40 + 1\n",
    "\n",
    "print(\"Задача № 1: \", variant % 3 + 1)\n",
    "print(\"Задача № 2: \", variant % 2 + 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d61a74c-af6f-4b70-b768-89b1cb2017bf",
   "metadata": {},
   "source": [
    "Датасеты\n",
    "\n",
    "hadoop fs -mkdir /dataset/hw4/small\n",
    "\n",
    "hdfs dfs -put /home/ubuntu/_practice/hw4/small/links.csv /dataset/hw4/small/links.csv\n",
    "hdfs dfs -put /home/ubuntu/_practice/hw4/small/movies.csv /dataset/hw4/small/movies.csv\n",
    "hdfs dfs -put /home/ubuntu/_practice/hw4/small/ratings.csv /dataset/hw4/small/ratings.csv\n",
    "hdfs dfs -put /home/ubuntu/_practice/hw4/small/tags.csv /dataset/hw4/small/tags.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "374441db-c007-4d7d-802f-6087ee079744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.4\n"
     ]
    }
   ],
   "source": [
    "# зависимости из дз1\n",
    "import os\n",
    "\n",
    "# пути к Java и Spark\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/ubuntu/_practice/spark-3.5.4-bin-hadoop3\"\n",
    "os.environ[\"PATH\"] += os.pathsep + os.path.join(os.environ[\"SPARK_HOME\"], \"bin\")\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "print(pyspark.__version__)\n",
    "\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f7a01f-d0a8-4b02-bda2-0ba1709b3af7",
   "metadata": {},
   "source": [
    "**Задание 1. Анализ датасета**\n",
    "\n",
    "Вариант 1. Animation, Romance, Documentary\n",
    "\n",
    "⚠️ Замечание: Один фильм может принадлежать разным жанрам\n",
    "\n",
    "1. Выведите данные, сопоставляющие жанры и количество фильмов\n",
    "2. Выведите первые 10 фильмов с наибольшим количеством рейтингов для каждого жанра в соответствии с вариантом\n",
    "3. Выведите первые 10 фильмов с наименьшим количеством рейтингов (но больше 10) для каждого жанра в соответствии с вариантом\n",
    "4. Выведите первые 10 фильмов с наибольшим средним рейтингом при количестве рейтингов больше 10 для каждого жанра в соответствии с вариантом\n",
    "5. Выведите первые 10 фильмов с наименьшим средним рейтингом при количестве рейтингов больше 10 для каждого жанра в соответствии с вариантом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3badb9f-ce6a-4f78-9f17-c0bd24c7cc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/13 23:11:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, explode, split, count, mean, desc, asc\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "# Инициализация SparkSession\n",
    "spark = SparkSession.builder.appName(\"Movies Marchuk\").getOrCreate()\n",
    "\n",
    "# Пути к файлам в HDFS\n",
    "movies_path = \"/dataset/hw4/small/movies.csv\"\n",
    "ratings_path = \"/dataset/hw4/small/ratings.csv\"\n",
    "\n",
    "# Загрузка данных\n",
    "movies_df = spark.read.csv(movies_path, header=True, inferSchema=True)\n",
    "ratings_df = spark.read.csv(ratings_path, header=True, inferSchema=True)\n",
    "\n",
    "# Разделение жанров на отдельные строки\n",
    "movies_with_genres = movies_df.withColumn(\"genre\", explode(split(col(\"genres\"), \"\\\\|\")))\n",
    "\n",
    "# Фильтрация по целевым жанрам\n",
    "target_genres = [\"Animation\", \"Romance\", \"Documentary\"]\n",
    "movies_target_genres = movies_with_genres.filter(col(\"genre\").isin(target_genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ccf337d-924d-42dd-9bf6-d94a442538f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|      genre|movie_count|\n",
      "+-----------+-----------+\n",
      "|    Romance|       1596|\n",
      "|Documentary|        440|\n",
      "|  Animation|        611|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Сопоставление жанров и количества фильмов\n",
    "genre_counts = movies_target_genres.groupBy(\"genre\").agg(count(\"*\").alias(\"movie_count\"))\n",
    "genre_counts.show()\n",
    "\n",
    "# Присоединение рейтингов\n",
    "movies_ratings = movies_target_genres.join(ratings_df, \"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f1c7199-b118-4962-91f1-3e189a4e4568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------------------------------------------------+------------+----+\n",
      "|genre      |movieId|title                                                  |rating_count|rank|\n",
      "+-----------+-------+-------------------------------------------------------+------------+----+\n",
      "|Animation  |1      |Toy Story (1995)                                       |215         |1   |\n",
      "|Animation  |588    |Aladdin (1992)                                         |183         |2   |\n",
      "|Animation  |364    |Lion King, The (1994)                                  |172         |3   |\n",
      "|Animation  |4306   |Shrek (2001)                                           |170         |4   |\n",
      "|Animation  |595    |Beauty and the Beast (1991)                            |146         |5   |\n",
      "|Animation  |6377   |Finding Nemo (2003)                                    |141         |6   |\n",
      "|Animation  |4886   |Monsters, Inc. (2001)                                  |132         |7   |\n",
      "|Animation  |8961   |Incredibles, The (2004)                                |125         |8   |\n",
      "|Animation  |68954  |Up (2009)                                              |105         |9   |\n",
      "|Animation  |60069  |WALL·E (2008)                                          |104         |10  |\n",
      "|Documentary|5669   |Bowling for Columbine (2002)                           |58          |1   |\n",
      "|Documentary|8464   |Super Size Me (2004)                                   |50          |2   |\n",
      "|Documentary|8622   |Fahrenheit 9/11 (2004)                                 |37          |3   |\n",
      "|Documentary|2064   |Roger & Me (1989)                                      |31          |4   |\n",
      "|Documentary|246    |Hoop Dreams (1994)                                     |29          |5   |\n",
      "|Documentary|34072  |March of the Penguins (Marche de l'empereur, La) (2005)|18          |6   |\n",
      "|Documentary|162    |Crumb (1994)                                           |17          |7   |\n",
      "|Documentary|5785   |Jackass: The Movie (2002)                              |17          |8   |\n",
      "|Documentary|53894  |Sicko (2007)                                           |14          |9   |\n",
      "|Documentary|77455  |Exit Through the Gift Shop (2010)                      |13          |10  |\n",
      "|Romance    |356    |Forrest Gump (1994)                                    |329         |1   |\n",
      "|Romance    |2858   |American Beauty (1999)                                 |204         |2   |\n",
      "|Romance    |380    |True Lies (1994)                                       |178         |3   |\n",
      "|Romance    |377    |Speed (1994)                                           |171         |4   |\n",
      "|Romance    |4306   |Shrek (2001)                                           |170         |5   |\n",
      "|Romance    |595    |Beauty and the Beast (1991)                            |146         |6   |\n",
      "|Romance    |1265   |Groundhog Day (1993)                                   |143         |7   |\n",
      "|Romance    |1197   |Princess Bride, The (1987)                             |142         |8   |\n",
      "|Romance    |1704   |Good Will Hunting (1997)                               |141         |9   |\n",
      "|Romance    |1721   |Titanic (1997)                                         |140         |10  |\n",
      "+-----------+-------+-------------------------------------------------------+------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Топ-10 фильмов с наибольшим количеством рейтингов для каждого жанра\n",
    "\n",
    "# Создаем окно для нумерации фильмов в каждом жанре\n",
    "window_spec = Window.partitionBy(\"genre\").orderBy(col(\"rating_count\").desc())\n",
    "\n",
    "# Добавляем колонку с порядковым номером фильма в жанре\n",
    "ranked_movies = (\n",
    "    movies_ratings.groupBy(\"genre\", \"movieId\", \"title\")\n",
    "    .agg(count(\"rating\").alias(\"rating_count\"))\n",
    "    .withColumn(\"rank\", row_number().over(window_spec))\n",
    ")\n",
    "\n",
    "# Фильтруем, оставляя только топ-10 фильмов в каждом жанре\n",
    "top_10_rated_per_genre = ranked_movies.filter(col(\"rank\") <= 10)\n",
    "\n",
    "# Сортируем и отображаем результаты\n",
    "top_10_rated_per_genre = top_10_rated_per_genre.orderBy(\"genre\", \"rank\")\n",
    "top_10_rated_per_genre.show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f02f7b7-fbad-430a-9c7b-049bc1fcf66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------------------------------------------------------------------------+------------+----+\n",
      "|genre      |movieId|title                                                                     |rating_count|rank|\n",
      "+-----------+-------+--------------------------------------------------------------------------+------------+----+\n",
      "|Animation  |55442  |Persepolis (2007)                                                         |11          |1   |\n",
      "|Animation  |49274  |Happy Feet (2006)                                                         |11          |2   |\n",
      "|Animation  |97225  |Hotel Transylvania (2012)                                                 |11          |3   |\n",
      "|Animation  |8965   |Polar Express, The (2004)                                                 |11          |4   |\n",
      "|Animation  |709    |Oliver & Company (1988)                                                   |11          |5   |\n",
      "|Animation  |52435  |How the Grinch Stole Christmas! (1966)                                    |11          |6   |\n",
      "|Animation  |631    |All Dogs Go to Heaven 2 (1996)                                            |11          |7   |\n",
      "|Animation  |65261  |Ponyo (Gake no ue no Ponyo) (2008)                                        |11          |8   |\n",
      "|Animation  |52287  |Meet the Robinsons (2007)                                                 |11          |9   |\n",
      "|Animation  |72737  |Princess and the Frog, The (2009)                                         |12          |10  |\n",
      "|Documentary|1289   |Koyaanisqatsi (a.k.a. Koyaanisqatsi: Life Out of Balance) (1983)          |11          |1   |\n",
      "|Documentary|1189   |Thin Blue Line, The (1988)                                                |11          |2   |\n",
      "|Documentary|54881  |King of Kong, The (2007)                                                  |12          |3   |\n",
      "|Documentary|80906  |Inside Job (2010)                                                         |12          |4   |\n",
      "|Documentary|77455  |Exit Through the Gift Shop (2010)                                         |13          |5   |\n",
      "|Documentary|45950  |Inconvenient Truth, An (2006)                                             |13          |6   |\n",
      "|Documentary|6331   |Spellbound (2002)                                                         |13          |7   |\n",
      "|Documentary|7156   |Fog of War: Eleven Lessons from the Life of Robert S. McNamara, The (2003)|13          |8   |\n",
      "|Documentary|53894  |Sicko (2007)                                                              |14          |9   |\n",
      "|Documentary|162    |Crumb (1994)                                                              |17          |10  |\n",
      "|Romance    |48082  |Science of Sleep, The (La science des rêves) (2006)                       |11          |1   |\n",
      "|Romance    |3259   |Far and Away (1992)                                                       |11          |2   |\n",
      "|Romance    |1735   |Great Expectations (1998)                                                 |11          |3   |\n",
      "|Romance    |89904  |The Artist (2011)                                                         |11          |4   |\n",
      "|Romance    |5812   |Far from Heaven (2002)                                                    |11          |5   |\n",
      "|Romance    |59725  |Sex and the City (2008)                                                   |11          |6   |\n",
      "|Romance    |3261   |Singles (1992)                                                            |11          |7   |\n",
      "|Romance    |54190  |Across the Universe (2007)                                                |11          |8   |\n",
      "|Romance    |31433  |Wedding Date, The (2005)                                                  |11          |9   |\n",
      "|Romance    |1944   |From Here to Eternity (1953)                                              |11          |10  |\n",
      "+-----------+-------+--------------------------------------------------------------------------+------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Топ-10 фильмов с наименьшим количеством рейтингов (>10) для каждого жанра\n",
    "window_spec_rating_count = Window.partitionBy(\"genre\").orderBy(col(\"rating_count\").asc())\n",
    "least_10_rated_per_genre = (\n",
    "    movies_ratings.groupBy(\"genre\", \"movieId\", \"title\")\n",
    "    .agg(count(\"rating\").alias(\"rating_count\"))\n",
    "    .filter(col(\"rating_count\") > 10)  # Условие > 10\n",
    "    .withColumn(\"rank\", row_number().over(window_spec_rating_count))\n",
    "    .filter(col(\"rank\") <= 10)  # Топ-10 для каждого жанра\n",
    "    .orderBy(\"genre\", \"rank\")\n",
    ")\n",
    "least_10_rated_per_genre.show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46879d46-1ddf-4fbb-8437-1f23721f3d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------------------------------------------------------------------------+------------+------------------+----+\n",
      "|genre      |movieId|title                                                                     |rating_count|avg_rating        |rank|\n",
      "+-----------+-------+--------------------------------------------------------------------------+------------+------------------+----+\n",
      "|Animation  |3429   |Creature Comforts (1989)                                                  |12          |4.25              |1   |\n",
      "|Animation  |55442  |Persepolis (2007)                                                         |11          |4.181818181818182 |2   |\n",
      "|Animation  |5690   |Grave of the Fireflies (Hotaru no haka) (1988)                            |16          |4.15625           |3   |\n",
      "|Animation  |5618   |Spirited Away (Sen to Chihiro no kamikakushi) (2001)                      |87          |4.155172413793103 |4   |\n",
      "|Animation  |741    |Ghost in the Shell (Kôkaku kidôtai) (1995)                                |27          |4.148148148148148 |5   |\n",
      "|Animation  |3213   |Batman: Mask of the Phantasm (1993)                                       |13          |4.115384615384615 |6   |\n",
      "|Animation  |78499  |Toy Story 3 (2010)                                                        |55          |4.109090909090909 |7   |\n",
      "|Animation  |720    |Wallace & Gromit: The Best of Aardman Animation (1996)                    |27          |4.092592592592593 |8   |\n",
      "|Animation  |1223   |Grand Day Out with Wallace and Gromit, A (1989)                           |28          |4.089285714285714 |9   |\n",
      "|Animation  |72226  |Fantastic Mr. Fox (2009)                                                  |18          |4.083333333333333 |10  |\n",
      "|Documentary|7156   |Fog of War: Eleven Lessons from the Life of Robert S. McNamara, The (2003)|13          |4.3076923076923075|1   |\n",
      "|Documentary|246    |Hoop Dreams (1994)                                                        |29          |4.293103448275862 |2   |\n",
      "|Documentary|80906  |Inside Job (2010)                                                         |12          |4.291666666666667 |3   |\n",
      "|Documentary|162    |Crumb (1994)                                                              |17          |4.205882352941177 |4   |\n",
      "|Documentary|77455  |Exit Through the Gift Shop (2010)                                         |13          |4.038461538461538 |5   |\n",
      "|Documentary|1189   |Thin Blue Line, The (1988)                                                |11          |4.0               |6   |\n",
      "|Documentary|6331   |Spellbound (2002)                                                         |13          |3.923076923076923 |7   |\n",
      "|Documentary|54881  |King of Kong, The (2007)                                                  |12          |3.9166666666666665|8   |\n",
      "|Documentary|1289   |Koyaanisqatsi (a.k.a. Koyaanisqatsi: Life Out of Balance) (1983)          |11          |3.8636363636363638|9   |\n",
      "|Documentary|2064   |Roger & Me (1989)                                                         |31          |3.838709677419355 |10  |\n",
      "|Romance    |951    |His Girl Friday (1940)                                                    |14          |4.392857142857143 |1   |\n",
      "|Romance    |922    |Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)                             |27          |4.333333333333333 |2   |\n",
      "|Romance    |905    |It Happened One Night (1934)                                              |14          |4.321428571428571 |3   |\n",
      "|Romance    |898    |Philadelphia Story, The (1940)                                            |29          |4.310344827586207 |4   |\n",
      "|Romance    |1235   |Harold and Maude (1971)                                                   |26          |4.288461538461538 |5   |\n",
      "|Romance    |930    |Notorious (1946)                                                          |20          |4.25              |6   |\n",
      "|Romance    |912    |Casablanca (1942)                                                         |100         |4.24              |7   |\n",
      "|Romance    |1197   |Princess Bride, The (1987)                                                |142         |4.232394366197183 |8   |\n",
      "|Romance    |28     |Persuasion (1995)                                                         |11          |4.2272727272727275|9   |\n",
      "|Romance    |933    |To Catch a Thief (1955)                                                   |23          |4.217391304347826 |10  |\n",
      "+-----------+-------+--------------------------------------------------------------------------+------------+------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Топ-10 фильмов с наибольшим средним рейтингом (>10 рейтингов) для каждого жанра\n",
    "window_spec_avg_rating_desc = Window.partitionBy(\"genre\").orderBy(col(\"avg_rating\").desc())\n",
    "top_10_avg_rated_per_genre = (\n",
    "    movies_ratings.groupBy(\"genre\", \"movieId\", \"title\")\n",
    "    .agg(\n",
    "        count(\"rating\").alias(\"rating_count\"),\n",
    "        mean(\"rating\").alias(\"avg_rating\")\n",
    "    )\n",
    "    .filter(col(\"rating_count\") > 10)  # Условие > 10 рейтингов\n",
    "    .withColumn(\"rank\", row_number().over(window_spec_avg_rating_desc))\n",
    "    .filter(col(\"rank\") <= 10)  # Топ-10 для каждого жанра\n",
    "    .orderBy(\"genre\", \"rank\")\n",
    ")\n",
    "top_10_avg_rated_per_genre.show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11c6efcf-6eb2-4d6a-8c85-41ab8a90275e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+----------------------------------------------------------------+------------+------------------+----+\n",
      "|genre      |movieId|title                                                           |rating_count|avg_rating        |rank|\n",
      "+-----------+-------+----------------------------------------------------------------+------------+------------------+----+\n",
      "|Animation  |8907   |Shark Tale (2004)                                               |13          |2.3461538461538463|1   |\n",
      "|Animation  |69644  |Ice Age: Dawn of the Dinosaurs (2009)                           |14          |2.607142857142857 |2   |\n",
      "|Animation  |49274  |Happy Feet (2006)                                               |11          |2.6818181818181817|3   |\n",
      "|Animation  |2123   |All Dogs Go to Heaven (1989)                                    |15          |2.7               |4   |\n",
      "|Animation  |673    |Space Jam (1996)                                                |53          |2.707547169811321 |5   |\n",
      "|Animation  |1030   |Pete's Dragon (1977)                                            |15          |2.7666666666666666|6   |\n",
      "|Animation  |1920   |Small Soldiers (1998)                                           |18          |2.8333333333333335|7   |\n",
      "|Animation  |1405   |Beavis and Butt-Head Do America (1996)                          |31          |2.935483870967742 |8   |\n",
      "|Animation  |239    |Goofy Movie, A (1995)                                           |17          |3.0               |9   |\n",
      "|Animation  |53121  |Shrek the Third (2007)                                          |21          |3.0238095238095237|10  |\n",
      "|Documentary|8622   |Fahrenheit 9/11 (2004)                                          |37          |3.4864864864864864|1   |\n",
      "|Documentary|5785   |Jackass: The Movie (2002)                                       |17          |3.5               |2   |\n",
      "|Documentary|8464   |Super Size Me (2004)                                            |50          |3.51              |3   |\n",
      "|Documentary|34072  |March of the Penguins (Marche de l'empereur, La) (2005)         |18          |3.5555555555555554|4   |\n",
      "|Documentary|45950  |Inconvenient Truth, An (2006)                                   |13          |3.576923076923077 |5   |\n",
      "|Documentary|53894  |Sicko (2007)                                                    |14          |3.7142857142857144|6   |\n",
      "|Documentary|5669   |Bowling for Columbine (2002)                                    |58          |3.7758620689655173|7   |\n",
      "|Documentary|2064   |Roger & Me (1989)                                               |31          |3.838709677419355 |8   |\n",
      "|Documentary|1289   |Koyaanisqatsi (a.k.a. Koyaanisqatsi: Life Out of Balance) (1983)|11          |3.8636363636363638|9   |\n",
      "|Documentary|54881  |King of Kong, The (2007)                                        |12          |3.9166666666666665|10  |\n",
      "|Romance    |1556   |Speed 2: Cruise Control (1997)                                  |19          |1.605263157894737 |1   |\n",
      "|Romance    |1381   |Grease 2 (1982)                                                 |19          |2.0789473684210527|2   |\n",
      "|Romance    |33836  |Bewitched (2005)                                                |13          |2.269230769230769 |3   |\n",
      "|Romance    |502    |Next Karate Kid, The (1994)                                     |15          |2.3666666666666667|4   |\n",
      "|Romance    |4247   |Joe Dirt (2001)                                                 |21          |2.380952380952381 |5   |\n",
      "|Romance    |4621   |Look Who's Talking (1989)                                       |18          |2.388888888888889 |6   |\n",
      "|Romance    |59725  |Sex and the City (2008)                                         |11          |2.409090909090909 |7   |\n",
      "|Romance    |63992  |Twilight (2008)                                                 |22          |2.409090909090909 |8   |\n",
      "|Romance    |3824   |Autumn in New York (2000)                                       |11          |2.409090909090909 |9   |\n",
      "|Romance    |4153   |Down to Earth (2001)                                            |12          |2.4166666666666665|10  |\n",
      "+-----------+-------+----------------------------------------------------------------+------------+------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Топ-10 фильмов с наименьшим средним рейтингом (>10 рейтингов) для каждого жанра\n",
    "window_spec_avg_rating = Window.partitionBy(\"genre\").orderBy(col(\"avg_rating\").asc())\n",
    "least_10_avg_rated_per_genre = (\n",
    "    movies_ratings.groupBy(\"genre\", \"movieId\", \"title\")\n",
    "    .agg(\n",
    "        count(\"rating\").alias(\"rating_count\"),\n",
    "        mean(\"rating\").alias(\"avg_rating\")\n",
    "    )\n",
    "    .filter(col(\"rating_count\") > 10)  # Условие > 10 рейтингов\n",
    "    .withColumn(\"rank\", row_number().over(window_spec_avg_rating))\n",
    "    .filter(col(\"rank\") <= 10)  # Топ-10 для каждого жанра\n",
    "    .orderBy(\"genre\", \"rank\")\n",
    ")\n",
    "least_10_avg_rated_per_genre.show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87ddcee5-9f8c-4c5b-8a27-11c6d7084273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Остановка SparkSession\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8216f13-331f-4f04-8f9a-67afb9a8822d",
   "metadata": {},
   "source": [
    "**Задание 2. Коллаборативная фильтрация**\n",
    "\n",
    "Вариант 2. По схожести объектов\n",
    "\n",
    "1. Разделите данные с рейтингами на обучающее (train_init - 0.8) и тестовое подмножества (test - 0.2), определите среднее значение рейтинга в обучающем подмножестве и вычислите rmse для тестового подмножества, если для всех значений из test предсказывается среднее значение рейтинга\n",
    "2. Реализуйте коллаборативную фильтрацию в соответствии с вариантом. Для определения схожести используйте train_init, для расчета rmse - test\n",
    "3. Определите rmse для тестового подмножества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b9d70df-47f6-4665-a397-59b7d2ca109a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение рейтинга в train_init: 3.50\n",
      "RMSE при предсказании среднего рейтинга: 1.0504\n"
     ]
    }
   ],
   "source": [
    "# 1. Подготовка данных. Разделение данных на обучающую и тестовую выборки, \n",
    "#    вычисление среднего значения рейтинга для обучающей выборки и RMSE для тестовой выборки.\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, explode, split, count, mean, desc, asc, lit, avg, sqrt\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "\n",
    "# Инициализация SparkSession\n",
    "spark = SparkSession.builder.appName(\"Movies2 Marchuk\").getOrCreate()\n",
    "\n",
    "# Загрузка данных из HDFS\n",
    "ratings = spark.read.csv(\"/dataset/hw4/small/ratings.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Разделение на train_init (80%) и test (20%)\n",
    "train_init, test = ratings.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Среднее значение рейтинга в train_init\n",
    "mean_rating = train_init.select(avg(\"rating\").alias(\"mean_rating\")).collect()[0][\"mean_rating\"]\n",
    "\n",
    "# Предсказание среднего значения для тестового набора\n",
    "test_with_predictions = test.withColumn(\"prediction\", lit(mean_rating))\n",
    "\n",
    "# Вычисление RMSE для тестового подмножества\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse_mean = evaluator.evaluate(test_with_predictions)\n",
    "\n",
    "print(f\"Среднее значение рейтинга в train_init: {mean_rating:.2f}\")\n",
    "print(f\"RMSE при предсказании среднего рейтинга: {rmse_mean:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8243be6-ba4f-4953-89b2-f7e9ffeccab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/13 23:11:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:11:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:11:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:11:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:11:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:11:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:11:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:11:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:11:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:11:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:11:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:11:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:11:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:11:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:11:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:11:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:11:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:11:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:11:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:11:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:11:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 21:==============================================>           (4 + 1) / 5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE для коллаборативной фильтрации: 1.0545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#2. Реализуйте коллаборативную фильтрацию в соответствии с вариантом. \n",
    "#   Для определения схожести используйте train_init, для расчета rmse - test\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import col, sqrt, sum as spark_sum\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# 1. Создание матрицы рейтингов \"userId x movieId\" для train_init\n",
    "ratings_matrix = (\n",
    "    train_init.groupBy(\"userId\", \"movieId\")\n",
    "    .agg(mean(\"rating\").alias(\"rating\"))\n",
    ")\n",
    "\n",
    "# 2. Вычисление косинусного сходства между фильмами\n",
    "ratings_self_join = ratings_matrix.alias(\"r1\").join(\n",
    "    ratings_matrix.alias(\"r2\"),\n",
    "    col(\"r1.userId\") == col(\"r2.userId\")  # Сравнение по одному и тому же пользователю\n",
    ")\n",
    "\n",
    "# Подсчет числителя (скалярное произведение) и знаменателя (длины векторов)\n",
    "movie_similarity = (\n",
    "    ratings_self_join.groupBy(\"r1.movieId\", \"r2.movieId\")\n",
    "    .agg(\n",
    "        spark_sum(col(\"r1.rating\") * col(\"r2.rating\")).alias(\"dot_product\"),\n",
    "        sqrt(spark_sum(col(\"r1.rating\")**2)).alias(\"norm_r1\"),\n",
    "        sqrt(spark_sum(col(\"r2.rating\")**2)).alias(\"norm_r2\"),\n",
    "    )\n",
    "    .withColumn(\"similarity\", col(\"dot_product\") / (col(\"norm_r1\") * col(\"norm_r2\")))\n",
    "    .filter(col(\"r1.movieId\") != col(\"r2.movieId\"))  # Убираем сравнение фильма с самим собой\n",
    ")\n",
    "# 3. Генерация предсказаний\n",
    "# Для каждого фильма из test находим его ближайших соседей в train_init\n",
    "predictions = (\n",
    "    test.alias(\"t\").join(\n",
    "        movie_similarity.select(\n",
    "            col(\"r1.movieId\").alias(\"movieId_test\"),  # Переименуем столбцы для удобства\n",
    "            col(\"r2.movieId\").alias(\"movieId_train\"),\n",
    "            \"similarity\"\n",
    "        ).alias(\"ms\"),\n",
    "        col(\"t.movieId\") == col(\"ms.movieId_test\"),  # Связываем фильмы из тестового множества с похожими\n",
    "        \"left\"\n",
    "    )\n",
    "    .join(\n",
    "        train_init.alias(\"tr\"),\n",
    "        col(\"ms.movieId_train\") == col(\"tr.movieId\"),  # Связываем с рейтингами соседей\n",
    "        \"left\"\n",
    "    )\n",
    "    .groupBy(\"t.userId\", \"t.movieId\")\n",
    "    .agg(\n",
    "        spark_sum(col(\"ms.similarity\") * col(\"tr.rating\")).alias(\"weighted_sum\"),\n",
    "        spark_sum(col(\"ms.similarity\")).alias(\"similarity_sum\"),\n",
    "    )\n",
    "    .withColumn(\"prediction\", col(\"weighted_sum\") / col(\"similarity_sum\"))\n",
    "    .select(\"userId\", \"movieId\", \"prediction\")\n",
    ")\n",
    "\n",
    "# 4. Оценка качества модели (RMSE)\n",
    "# Объединяем предсказания с реальными рейтингами\n",
    "test_with_predictions = test.join(predictions, [\"userId\", \"movieId\"], \"left\")\n",
    "\n",
    "# Заполняем пропущенные значения средним рейтингом (если фильм не имеет похожих)\n",
    "test_with_predictions = test_with_predictions.fillna(mean_rating, subset=[\"prediction\"])\n",
    "\n",
    "# Вычисление RMSE\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse_collaborative = evaluator.evaluate(test_with_predictions)\n",
    "\n",
    "print(f\"RMSE для коллаборативной фильтрации: {rmse_collaborative:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e92b1c4-752e-4c07-ac86-8394384fadfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/13 23:12:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/13 23:12:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 45:==================================>                       (3 + 2) / 5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE для коллаборативной фильтрации: 1.0545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 3. Определите rmse для тестового подмножества\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Оценка качества модели (RMSE)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "# Вычисление RMSE\n",
    "rmse_collaborative = evaluator.evaluate(test_with_predictions)\n",
    "\n",
    "print(f\"RMSE для коллаборативной фильтрации: {rmse_collaborative:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36f32bcd-69f9-4821-811b-3844205dac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Остановка SparkSession\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962954bf-9a21-4674-b612-1269f71d9e80",
   "metadata": {},
   "source": [
    "**Задание 3. Факторизация матрицы**\n",
    "1. Выберите модель ALS по минимальному значению rmse. Для этого используйте кросс-валидацию k-folds c k=4\n",
    "\n",
    "Параметры:\n",
    "\n",
    "Количество факторов: [5, 10, 15]\n",
    "\n",
    "Регуляризация: [0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "⚠️ Замечание: Если какие-то элементы из тестового/валидационного подмножества не встречались в обучающем, то rmse будет NaN\n",
    "\n",
    "2. Сравните результаты рекомендаций посредством коллаборативной фильтрации и факторизации матрицы рейтингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06dd561c-5f77-4d17-9f88-1a4045d5bf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/13 23:13:07 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/01/13 23:13:07 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factor: 5, RegParam: 0.001, RMSE: 1.1978\n",
      "Factor: 5, RegParam: 0.01, RMSE: 1.0453\n",
      "Factor: 5, RegParam: 0.1, RMSE: 0.8875\n",
      "Factor: 5, RegParam: 1, RMSE: 1.3214\n",
      "Factor: 5, RegParam: 10, RMSE: 3.6638\n",
      "Factor: 10, RegParam: 0.001, RMSE: 1.3454\n",
      "Factor: 10, RegParam: 0.01, RMSE: 1.1476\n",
      "Factor: 10, RegParam: 0.1, RMSE: 0.8915\n",
      "Factor: 10, RegParam: 1, RMSE: 1.3214\n",
      "Factor: 10, RegParam: 10, RMSE: 3.6638\n",
      "Factor: 15, RegParam: 0.001, RMSE: 1.4202\n",
      "Factor: 15, RegParam: 0.01, RMSE: 1.2101\n",
      "Factor: 15, RegParam: 0.1, RMSE: 0.8918\n",
      "Factor: 15, RegParam: 1, RMSE: 1.3214\n",
      "Factor: 15, RegParam: 10, RMSE: 3.6638\n",
      "\n",
      "Лучшие параметры: {'factor': 5, 'regParam': 0.1}\n",
      "Минимальное RMSE: 0.8875\n"
     ]
    }
   ],
   "source": [
    "# 1. Выберите модель ALS по минимальному значению rmse. Для этого используйте кросс-валидацию k-folds c k=4\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "import numpy as np\n",
    "\n",
    "# Инициализация SparkSession\n",
    "spark = SparkSession.builder.appName(\"Movies3  Marchuk\").getOrCreate()\n",
    "\n",
    "# Загрузка данных\n",
    "ratings = spark.read.csv(\"/dataset/hw4/small/ratings.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Параметры для кросс-валидации\n",
    "k_folds = 4\n",
    "factors = [5, 10, 15]\n",
    "reg_params = [0.001, 0.01, 0.1, 1, 10]\n",
    "seed = 42\n",
    "\n",
    "# Функция для вычисления RMSE\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "# Кросс-валидация\n",
    "min_rmse = float(\"inf\")\n",
    "best_model_params = None\n",
    "\n",
    "# Создаем k фолдов\n",
    "folds = ratings.randomSplit([1.0 / k_folds] * k_folds, seed=seed)\n",
    "\n",
    "for factor in factors:\n",
    "    for reg_param in reg_params:\n",
    "        fold_rmse = []\n",
    "        \n",
    "        for i in range(k_folds):\n",
    "            # Определяем обучающую и валидационную выборки\n",
    "            validation = folds[i]\n",
    "            train = spark.createDataFrame(\n",
    "                [row for j, fold in enumerate(folds) if j != i for row in fold.collect()]\n",
    "            )\n",
    "            \n",
    "            # Инициализация модели ALS\n",
    "            als = ALS(\n",
    "                maxIter=10,\n",
    "                rank=factor,\n",
    "                regParam=reg_param,\n",
    "                userCol=\"userId\",\n",
    "                itemCol=\"movieId\",\n",
    "                ratingCol=\"rating\",\n",
    "                coldStartStrategy=\"drop\",  # Убираем NaN предсказания\n",
    "                seed=seed,\n",
    "            )\n",
    "            \n",
    "            # Обучение модели\n",
    "            model = als.fit(train)\n",
    "            \n",
    "            # Предсказания на валидационном наборе\n",
    "            predictions = model.transform(validation)\n",
    "            \n",
    "            # Вычисление RMSE\n",
    "            rmse = evaluator.evaluate(predictions)\n",
    "            fold_rmse.append(rmse)\n",
    "        \n",
    "        # Среднее RMSE для текущих параметров\n",
    "        avg_rmse = np.mean(fold_rmse)\n",
    "        \n",
    "        print(f\"Factor: {factor}, RegParam: {reg_param}, RMSE: {avg_rmse:.4f}\")\n",
    "        \n",
    "        # Сохранение лучших параметров\n",
    "        if avg_rmse < min_rmse:\n",
    "            min_rmse = avg_rmse\n",
    "            best_model_params = {\"factor\": factor, \"regParam\": reg_param}\n",
    "\n",
    "print(f\"\\nЛучшие параметры: {best_model_params}\")\n",
    "print(f\"Минимальное RMSE: {min_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50efd4a6-6117-4993-bf88-9669e64db47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Остановка SparkSession\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc6c4fa-9983-4077-bd40-52ac190387ee",
   "metadata": {},
   "source": [
    "2. Сравните результаты рекомендаций посредством коллаборативной фильтрации и факторизации матрицы рейтингов\n",
    "\n",
    "Факторизация матрицы показала наилучший результат с минимальным RMSE 0.8875, что значительно лучше, чем предсказание среднего рейтинга и коллаборативная фильтрация по схожести объектов.\n",
    "Однако, если доступно мало данных или вычислительные ресурсы ограничены, использование предсказания среднего или коллаборативной фильтрации может быть оправдано.\n",
    "Для больших и сложных наборов данных корее всего больше подойдёт ALS, так как он лучше масштабируется и точнее захватывает скрытые паттерны в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22513d56-b374-4f6c-a8a5-72ed1b7075a8",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "**================================= БОЛЬШОЙ НАБОР ДАННЫХ =================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1673634-2a9a-4725-b652-b79659e4da97",
   "metadata": {},
   "source": [
    "Датасеты\n",
    "\n",
    "hadoop fs -mkdir /dataset/hw4/big\n",
    "\n",
    "hdfs dfs -put /home/ubuntu/_practice/hw4/big/links.csv /dataset/hw4/big/links.csv\n",
    "hdfs dfs -put /home/ubuntu/_practice/hw4/big/movies.csv /dataset/hw4/big/movies.csv\n",
    "hdfs dfs -put /home/ubuntu/_practice/hw4/big/ratings.csv /dataset/hw4/big/ratings.csv\n",
    "hdfs dfs -put /home/ubuntu/_practice/hw4/big/tags.csv /dataset/hw4/big/tags.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c7a6b12-54b4-4b40-b982-8a77e54f58f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, explode, split, count, mean, desc, asc\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "# Инициализация SparkSession\n",
    "spark = SparkSession.builder.appName(\"Movies Marchuk\").getOrCreate()\n",
    "\n",
    "# Пути к файлам в HDFS\n",
    "movies_path = \"/dataset/hw4/big/movies.csv\"\n",
    "ratings_path = \"/dataset/hw4/big/ratings.csv\"\n",
    "\n",
    "# Загрузка данных\n",
    "movies_df = spark.read.csv(movies_path, header=True, inferSchema=True)\n",
    "ratings_df = spark.read.csv(ratings_path, header=True, inferSchema=True)\n",
    "\n",
    "# Разделение жанров на отдельные строки\n",
    "movies_with_genres = movies_df.withColumn(\"genre\", explode(split(col(\"genres\"), \"\\\\|\")))\n",
    "\n",
    "# Фильтрация по целевым жанрам\n",
    "target_genres = [\"Animation\", \"Romance\", \"Documentary\"]\n",
    "movies_target_genres = movies_with_genres.filter(col(\"genre\").isin(target_genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce966b42-5c03-4e16-8999-f681b370da51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|      genre|movie_count|\n",
      "+-----------+-----------+\n",
      "|    Romance|      10172|\n",
      "|Documentary|       9283|\n",
      "|  Animation|       4579|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Сопоставление жанров и количества фильмов\n",
    "genre_counts = movies_target_genres.groupBy(\"genre\").agg(count(\"*\").alias(\"movie_count\"))\n",
    "genre_counts.show()\n",
    "\n",
    "# Присоединение рейтингов\n",
    "movies_ratings = movies_target_genres.join(ratings_df, \"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a645e032-8cc4-4a06-998d-7913d05a7edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:==========================================>                (5 + 2) / 7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------------------------------------------------+------------+----+\n",
      "|genre      |movieId|title                                                  |rating_count|rank|\n",
      "+-----------+-------+-------------------------------------------------------+------------+----+\n",
      "|Animation  |1      |Toy Story (1995)                                       |76813       |1   |\n",
      "|Animation  |4306   |Shrek (2001)                                           |58529       |2   |\n",
      "|Animation  |588    |Aladdin (1992)                                         |55791       |3   |\n",
      "|Animation  |364    |Lion King, The (1994)                                  |53509       |4   |\n",
      "|Animation  |4886   |Monsters, Inc. (2001)                                  |48441       |5   |\n",
      "|Animation  |6377   |Finding Nemo (2003)                                    |48124       |6   |\n",
      "|Animation  |595    |Beauty and the Beast (1991)                            |45404       |7   |\n",
      "|Animation  |8961   |Incredibles, The (2004)                                |42953       |8   |\n",
      "|Animation  |60069  |WALL·E (2008)                                          |42033       |9   |\n",
      "|Animation  |68954  |Up (2009)                                              |38751       |10  |\n",
      "|Documentary|5669   |Bowling for Columbine (2002)                           |16608       |1   |\n",
      "|Documentary|8464   |Super Size Me (2004)                                   |14077       |2   |\n",
      "|Documentary|246    |Hoop Dreams (1994)                                     |11731       |3   |\n",
      "|Documentary|8622   |Fahrenheit 9/11 (2004)                                 |11553       |4   |\n",
      "|Documentary|2064   |Roger & Me (1989)                                      |8296        |5   |\n",
      "|Documentary|162    |Crumb (1994)                                           |6758        |6   |\n",
      "|Documentary|5785   |Jackass: The Movie (2002)                              |5685        |7   |\n",
      "|Documentary|34072  |March of the Penguins (Marche de l'empereur, La) (2005)|4542        |8   |\n",
      "|Documentary|1147   |When We Were Kings (1996)                              |4207        |9   |\n",
      "|Documentary|45950  |Inconvenient Truth, An (2006)                          |4168        |10  |\n",
      "|Romance    |356    |Forrest Gump (1994)                                    |113581      |1   |\n",
      "|Romance    |2858   |American Beauty (1999)                                 |69902       |2   |\n",
      "|Romance    |4306   |Shrek (2001)                                           |58529       |3   |\n",
      "|Romance    |1704   |Good Will Hunting (1997)                               |54980       |4   |\n",
      "|Romance    |380    |True Lies (1994)                                       |52789       |5   |\n",
      "|Romance    |1197   |Princess Bride, The (1987)                             |50775       |6   |\n",
      "|Romance    |1721   |Titanic (1997)                                         |50706       |7   |\n",
      "|Romance    |377    |Speed (1994)                                           |49029       |8   |\n",
      "|Romance    |1265   |Groundhog Day (1993)                                   |47956       |9   |\n",
      "|Romance    |7361   |Eternal Sunshine of the Spotless Mind (2004)           |46292       |10  |\n",
      "+-----------+-------+-------------------------------------------------------+------------+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 2. Топ-10 фильмов с наибольшим количеством рейтингов для каждого жанра\n",
    "\n",
    "# Создаем окно для нумерации фильмов в каждом жанре\n",
    "window_spec = Window.partitionBy(\"genre\").orderBy(col(\"rating_count\").desc())\n",
    "\n",
    "# Добавляем колонку с порядковым номером фильма в жанре\n",
    "ranked_movies = (\n",
    "    movies_ratings.groupBy(\"genre\", \"movieId\", \"title\")\n",
    "    .agg(count(\"rating\").alias(\"rating_count\"))\n",
    "    .withColumn(\"rank\", row_number().over(window_spec))\n",
    ")\n",
    "\n",
    "# Фильтруем, оставляя только топ-10 фильмов в каждом жанре\n",
    "top_10_rated_per_genre = ranked_movies.filter(col(\"rank\") <= 10)\n",
    "\n",
    "# Сортируем и отображаем результаты\n",
    "top_10_rated_per_genre = top_10_rated_per_genre.orderBy(\"genre\", \"rank\")\n",
    "top_10_rated_per_genre.show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4eb9a44-6487-4596-b9fb-cbf7733c6507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:=================================================>        (6 + 1) / 7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------------------------------------------------------------------------------------------------+------------+----+\n",
      "|genre      |movieId|title                                                                                                  |rating_count|rank|\n",
      "+-----------+-------+-------------------------------------------------------------------------------------------------------+------------+----+\n",
      "|Animation  |182155 |Donald's Penguin (1939)                                                                                |11          |1   |\n",
      "|Animation  |182189 |The Pied Piper (1933)                                                                                  |11          |2   |\n",
      "|Animation  |216819 |The Art of Skiing (1941)                                                                               |11          |3   |\n",
      "|Animation  |251630 |Maggie Simpson in The Force Awakens from Its Nap (2021)                                                |11          |4   |\n",
      "|Animation  |178967 |The Lion, the Witch and the Wardrobe (1979)                                                            |11          |5   |\n",
      "|Animation  |238818 |The Games of Angels (1964)                                                                             |11          |6   |\n",
      "|Animation  |229593 |Alien Xmas (2020)                                                                                      |11          |7   |\n",
      "|Animation  |215413 |Away (2019)                                                                                            |11          |8   |\n",
      "|Animation  |204632 |Technological Threat (1988)                                                                            |11          |9   |\n",
      "|Animation  |163519 |Mouse in Manhattan (1945)                                                                              |11          |10  |\n",
      "|Documentary|70831  |Krakatoa: The Last Days (2006)                                                                         |11          |1   |\n",
      "|Documentary|278170 |Untold: The Rise and Fall of AND1 (2022)                                                               |11          |2   |\n",
      "|Documentary|162452 |Ghosts of Abu Ghraib (2007)                                                                            |11          |3   |\n",
      "|Documentary|163563 |Can We Take a Joke? (2015)                                                                             |11          |4   |\n",
      "|Documentary|211468 |The Rise of Jordan Peterson (2019)                                                                     |11          |5   |\n",
      "|Documentary|64385  |Body of War (2007)                                                                                     |11          |6   |\n",
      "|Documentary|67009  |Frontrunners (2008)                                                                                    |11          |7   |\n",
      "|Documentary|199596 |Toni Morrison: The Pieces I Am (2019)                                                                  |11          |8   |\n",
      "|Documentary|48626  |Once in a Lifetime: The Extraordinary Story of the New York Cosmos (2006)                              |11          |9   |\n",
      "|Documentary|133221 |The Man Who Skied Down Everest (1975)                                                                  |11          |10  |\n",
      "|Romance    |120290 |My Rainy Days (2009)                                                                                   |11          |1   |\n",
      "|Romance    |77835  |Stage Door Canteen (1943)                                                                              |11          |2   |\n",
      "|Romance    |199071 |Under the Eiffel Tower (2019)                                                                          |11          |3   |\n",
      "|Romance    |103528 |Shadow Riders, The (1982)                                                                              |11          |4   |\n",
      "|Romance    |210013 |Christmas with a Prince (2018)                                                                         |11          |5   |\n",
      "|Romance    |192581 |The Matchmaker's Playbook (2018)                                                                       |11          |6   |\n",
      "|Romance    |148640 |The American Mall (2008)                                                                               |11          |7   |\n",
      "|Romance    |7441   |Thousand Clouds of Peace, A (Mil nubes de paz cercan el cielo, amor, jamás acabarás de ser amor) (2003)|11          |8   |\n",
      "|Romance    |33852  |Becky Sharp (1935)                                                                                     |11          |9   |\n",
      "|Romance    |113630 |Man Who Couldn't Say No, The (Mies joka ei osannut sanoa EI) (1975)                                    |11          |10  |\n",
      "+-----------+-------+-------------------------------------------------------------------------------------------------------+------------+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 3. Топ-10 фильмов с наименьшим количеством рейтингов (>10) для каждого жанра\n",
    "window_spec_rating_count = Window.partitionBy(\"genre\").orderBy(col(\"rating_count\").asc())\n",
    "least_10_rated_per_genre = (\n",
    "    movies_ratings.groupBy(\"genre\", \"movieId\", \"title\")\n",
    "    .agg(count(\"rating\").alias(\"rating_count\"))\n",
    "    .filter(col(\"rating_count\") > 10)  # Условие > 10\n",
    "    .withColumn(\"rank\", row_number().over(window_spec_rating_count))\n",
    "    .filter(col(\"rank\") <= 10)  # Топ-10 для каждого жанра\n",
    "    .orderBy(\"genre\", \"rank\")\n",
    ")\n",
    "least_10_rated_per_genre.show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cb15932-3dde-41ec-84e5-10ca4d2b9174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:=================================>                        (4 + 3) / 7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-----------------------------------------------------------------------------+------------+------------------+----+\n",
      "|genre      |movieId|title                                                                        |rating_count|avg_rating        |rank|\n",
      "+-----------+-------+-----------------------------------------------------------------------------+------------+------------------+----+\n",
      "|Animation  |163809 |Over the Garden Wall (2013)                                                  |1430        |4.256993006993007 |1   |\n",
      "|Animation  |286897 |Spider-Man: Across the Spider-Verse (2023)                                   |528         |4.252840909090909 |2   |\n",
      "|Animation  |256991 |Adventure Time: Elements (2017)                                              |12          |4.25              |3   |\n",
      "|Animation  |5618   |Spirited Away (Sen to Chihiro no kamikakushi) (2001)                         |35375       |4.226035335689046 |4   |\n",
      "|Animation  |249180 |Violet Evergarden: The Movie (2020)                                          |25          |4.22              |5   |\n",
      "|Animation  |157373 |It's Such a Beautiful Day (2011)                                             |328         |4.1935975609756095|6   |\n",
      "|Animation  |195159 |Spider-Man: Into the Spider-Verse (2018)                                     |10885       |4.192053284336242 |7   |\n",
      "|Animation  |163134 |Your Name. (2016)                                                            |3940        |4.16751269035533  |8   |\n",
      "|Animation  |3000   |Princess Mononoke (Mononoke-hime) (1997)                                     |18226       |4.166026555470207 |9   |\n",
      "|Animation  |5971   |My Neighbor Totoro (Tonari no Totoro) (1988)                                 |14010       |4.163490364025696 |10  |\n",
      "|Documentary|102672 |New York: A Documentary Film (1999)                                          |11          |4.5               |1   |\n",
      "|Documentary|171011 |Planet Earth II (2016)                                                       |2041        |4.451739343459089 |2   |\n",
      "|Documentary|159817 |Planet Earth (2006)                                                          |3015        |4.448092868988391 |3   |\n",
      "|Documentary|215615 |Pink Floyd: Pulse (1995)                                                     |11          |4.318181818181818 |4   |\n",
      "|Documentary|179135 |Blue Planet II (2017)                                                        |1267        |4.312943962115233 |5   |\n",
      "|Documentary|142115 |The Blue Planet (2001)                                                       |1080        |4.25              |6   |\n",
      "|Documentary|147124 |The Roosevelts: An Intimate History (2014)                                   |46          |4.239130434782608 |7   |\n",
      "|Documentary|105250 |Century of the Self, The (2002)                                              |397         |4.221662468513854 |8   |\n",
      "|Documentary|239316 |Can't Get You Out of My Head: An Emotional History of the Modern World (2021)|47          |4.212765957446808 |9   |\n",
      "|Documentary|172725 |The Secret Life of Chaos (2010)                                              |12          |4.208333333333333 |10  |\n",
      "|Romance    |203847 |Kumbalangi Nights (2019)                                                     |18          |4.305555555555555 |1   |\n",
      "|Romance    |263965 |Downton Abbey: Christmas Special 2015 (2015)                                 |16          |4.25              |2   |\n",
      "|Romance    |249180 |Violet Evergarden: The Movie (2020)                                          |25          |4.22              |3   |\n",
      "|Romance    |122282 |Pride and Prejudice (1980)                                                   |58          |4.206896551724138 |4   |\n",
      "|Romance    |44555  |Lives of Others, The (Das leben der Anderen) (2006)                          |12626       |4.201409789323618 |5   |\n",
      "|Romance    |172719 |Notre Dame de Paris (1998)                                                   |15          |4.2               |6   |\n",
      "|Romance    |912    |Casablanca (1942)                                                            |34813       |4.195889466578577 |7   |\n",
      "|Romance    |922    |Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)                                |9627        |4.189934559052665 |8   |\n",
      "|Romance    |908    |North by Northwest (1959)                                                    |21883       |4.187337202394553 |9   |\n",
      "|Romance    |163134 |Your Name. (2016)                                                            |3940        |4.16751269035533  |10  |\n",
      "+-----------+-------+-----------------------------------------------------------------------------+------------+------------------+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 4. Топ-10 фильмов с наибольшим средним рейтингом (>10 рейтингов) для каждого жанра\n",
    "window_spec_avg_rating_desc = Window.partitionBy(\"genre\").orderBy(col(\"avg_rating\").desc())\n",
    "top_10_avg_rated_per_genre = (\n",
    "    movies_ratings.groupBy(\"genre\", \"movieId\", \"title\")\n",
    "    .agg(\n",
    "        count(\"rating\").alias(\"rating_count\"),\n",
    "        mean(\"rating\").alias(\"avg_rating\")\n",
    "    )\n",
    "    .filter(col(\"rating_count\") > 10)  # Условие > 10 рейтингов\n",
    "    .withColumn(\"rank\", row_number().over(window_spec_avg_rating_desc))\n",
    "    .filter(col(\"rank\") <= 10)  # Топ-10 для каждого жанра\n",
    "    .orderBy(\"genre\", \"rank\")\n",
    ")\n",
    "top_10_avg_rated_per_genre.show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f18f86a2-2008-4386-a780-25d002615b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:=========================================>                (5 + 2) / 7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------------------------------------------------------+------------+------------------+----+\n",
      "|genre      |movieId|title                                                   |rating_count|avg_rating        |rank|\n",
      "+-----------+-------+--------------------------------------------------------+------------+------------------+----+\n",
      "|Animation  |120222 |Foodfight! (2012)                                       |46          |0.9456521739130435|1   |\n",
      "|Animation  |170903 |The Swan Princess Christmas (2012)                      |11          |1.1363636363636365|2   |\n",
      "|Animation  |153564 |The Amazing Bulk (2012)                                 |15          |1.1666666666666667|3   |\n",
      "|Animation  |145096 |Barbie & Her Sisters in the Great Puppy Adventure (2015)|78          |1.1923076923076923|4   |\n",
      "|Animation  |151313 |Norm of the North (2016)                                |58          |1.5086206896551724|5   |\n",
      "|Animation  |6371   |Pokémon Heroes (2003)                                   |431         |1.519721577726218 |6   |\n",
      "|Animation  |5672   |Pokemon 4 Ever (a.k.a. Pokémon 4: The Movie) (2002)     |614         |1.5358306188925082|7   |\n",
      "|Animation  |136674 |Maya the Bee Movie (2014)                               |12          |1.5833333333333333|8   |\n",
      "|Animation  |200802 |Norm of the North: Keys to the Kingdom (2018)           |11          |1.5909090909090908|9   |\n",
      "|Animation  |179107 |The Legend of the Titanic (1999)                        |11          |1.6363636363636365|10  |\n",
      "|Documentary|107704 |Justin Bieber's Believe (2013)                          |21          |0.9285714285714286|1   |\n",
      "|Documentary|193183 |Death of a Nation (2018)                                |14          |1.2142857142857142|2   |\n",
      "|Documentary|5739   |Faces of Death 6 (1996)                                 |178         |1.2865168539325842|3   |\n",
      "|Documentary|121103 |Justin Bieber: Never Say Never (2011)                   |63          |1.2936507936507937|4   |\n",
      "|Documentary|5738   |Faces of Death 5 (1996)                                 |160         |1.365625          |5   |\n",
      "|Documentary|5740   |Faces of Death: Fact or Fiction? (1999)                 |133         |1.3759398496240602|6   |\n",
      "|Documentary|158731 |Kony 2012 (2012)                                        |13          |1.3846153846153846|7   |\n",
      "|Documentary|5737   |Faces of Death 4 (1990)                                 |185         |1.3945945945945946|8   |\n",
      "|Documentary|5736   |Faces of Death 3 (1985)                                 |207         |1.4951690821256038|9   |\n",
      "|Documentary|166741 |Electrocuting an Elephant (1903)                        |32          |1.53125           |10  |\n",
      "|Romance    |171479 |Kidnapping, Caucasian Style (2014)                      |17          |0.9117647058823529|1   |\n",
      "|Romance    |6483   |From Justin to Kelly (2003)                             |489         |1.0112474437627812|2   |\n",
      "|Romance    |4775   |Glitter (2001)                                          |788         |1.151015228426396 |3   |\n",
      "|Romance    |6587   |Gigli (2003)                                            |872         |1.2144495412844036|4   |\n",
      "|Romance    |103186 |Wedding Trough (Vase de noces) (1975)                   |15          |1.4333333333333333|5   |\n",
      "|Romance    |171555 |Classmates (2016)                                       |11          |1.5               |6   |\n",
      "|Romance    |145388 |Forever (2015)                                          |14          |1.5               |7   |\n",
      "|Romance    |153816 |Tashan (2008)                                           |11          |1.5454545454545454|8   |\n",
      "|Romance    |3390   |Shanghai Surprise (1986)                                |251         |1.5637450199203187|9   |\n",
      "|Romance    |43919  |Date Movie (2006)                                       |1130        |1.6176991150442477|10  |\n",
      "+-----------+-------+--------------------------------------------------------+------------+------------------+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 5. Топ-10 фильмов с наименьшим средним рейтингом (>10 рейтингов) для каждого жанра\n",
    "window_spec_avg_rating = Window.partitionBy(\"genre\").orderBy(col(\"avg_rating\").asc())\n",
    "least_10_avg_rated_per_genre = (\n",
    "    movies_ratings.groupBy(\"genre\", \"movieId\", \"title\")\n",
    "    .agg(\n",
    "        count(\"rating\").alias(\"rating_count\"),\n",
    "        mean(\"rating\").alias(\"avg_rating\")\n",
    "    )\n",
    "    .filter(col(\"rating_count\") > 10)  # Условие > 10 рейтингов\n",
    "    .withColumn(\"rank\", row_number().over(window_spec_avg_rating))\n",
    "    .filter(col(\"rank\") <= 10)  # Топ-10 для каждого жанра\n",
    "    .orderBy(\"genre\", \"rank\")\n",
    ")\n",
    "least_10_avg_rated_per_genre.show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8401f456-93cd-49a0-a8b3-de4555bf9d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Остановка SparkSession\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d7a4ad-feba-4fd3-aba7-c2a03514fae3",
   "metadata": {},
   "source": [
    "**Задание 2. Коллаборативная фильтрация**\n",
    "\n",
    "Вариант 2. По схожести объектов\n",
    "\n",
    "1. Разделите данные с рейтингами на обучающее (train_init - 0.8) и тестовое подмножества (test - 0.2), определите среднее значение рейтинга в обучающем подмножестве и вычислите rmse для тестового подмножества, если для всех значений из test предсказывается среднее значение рейтинга\n",
    "2. Реализуйте коллаборативную фильтрацию в соответствии с вариантом. Для определения схожести используйте train_init, для расчета rmse - test\n",
    "3. Определите rmse для тестового подмножества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa8ce36b-cb90-4972-a376-6c1321aa3f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:==================================================>        (6 + 1) / 7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение рейтинга в train_init: 3.54\n",
      "RMSE при предсказании среднего рейтинга: 1.0640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 1. Подготовка данных. Разделение данных на обучающую и тестовую выборки, \n",
    "#    вычисление среднего значения рейтинга для обучающей выборки и RMSE для тестовой выборки.\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, explode, split, count, mean, desc, asc, lit, avg, sqrt\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "\n",
    "# Инициализация SparkSession\n",
    "spark = SparkSession.builder.appName(\"Movies2 Marchuk\").getOrCreate()\n",
    "\n",
    "# Загрузка данных из HDFS\n",
    "ratings = spark.read.csv(\"/dataset/hw4/big/ratings.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Разделение на train_init (80%) и test (20%)\n",
    "train_init, test = ratings.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Среднее значение рейтинга в train_init\n",
    "mean_rating = train_init.select(avg(\"rating\").alias(\"mean_rating\")).collect()[0][\"mean_rating\"]\n",
    "\n",
    "# Предсказание среднего значения для тестового набора\n",
    "test_with_predictions = test.withColumn(\"prediction\", lit(mean_rating))\n",
    "\n",
    "# Вычисление RMSE для тестового подмножества\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse_mean = evaluator.evaluate(test_with_predictions)\n",
    "\n",
    "print(f\"Среднее значение рейтинга в train_init: {mean_rating:.2f}\")\n",
    "print(f\"RMSE при предсказании среднего рейтинга: {rmse_mean:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2045cab3-c253-4ebd-93c3-9268b069d036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Реализуйте коллаборативную фильтрацию в соответствии с вариантом. \n",
    "#   Для определения схожести используйте train_init, для расчета rmse - test\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import col, sqrt, sum as spark_sum\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# 1. Создание матрицы рейтингов \"userId x movieId\" для train_init\n",
    "ratings_matrix = (\n",
    "    train_init.groupBy(\"userId\", \"movieId\")\n",
    "    .agg(mean(\"rating\").alias(\"rating\"))\n",
    ")\n",
    "\n",
    "# 2. Вычисление косинусного сходства между фильмами\n",
    "ratings_self_join = ratings_matrix.alias(\"r1\").join(\n",
    "    ratings_matrix.alias(\"r2\"),\n",
    "    col(\"r1.userId\") == col(\"r2.userId\")  # Сравнение по одному и тому же пользователю\n",
    ")\n",
    "\n",
    "# Подсчет числителя (скалярное произведение) и знаменателя (длины векторов)\n",
    "movie_similarity = (\n",
    "    ratings_self_join.groupBy(\"r1.movieId\", \"r2.movieId\")\n",
    "    .agg(\n",
    "        spark_sum(col(\"r1.rating\") * col(\"r2.rating\")).alias(\"dot_product\"),\n",
    "        sqrt(spark_sum(col(\"r1.rating\")**2)).alias(\"norm_r1\"),\n",
    "        sqrt(spark_sum(col(\"r2.rating\")**2)).alias(\"norm_r2\"),\n",
    "    )\n",
    "    .withColumn(\"similarity\", col(\"dot_product\") / (col(\"norm_r1\") * col(\"norm_r2\")))\n",
    "    .filter(col(\"r1.movieId\") != col(\"r2.movieId\"))  # Убираем сравнение фильма с самим собой\n",
    ")\n",
    "# 3. Генерация предсказаний\n",
    "# Для каждого фильма из test находим его ближайших соседей в train_init\n",
    "predictions = (\n",
    "    test.alias(\"t\").join(\n",
    "        movie_similarity.select(\n",
    "            col(\"r1.movieId\").alias(\"movieId_test\"),  # Переименуем столбцы для удобства\n",
    "            col(\"r2.movieId\").alias(\"movieId_train\"),\n",
    "            \"similarity\"\n",
    "        ).alias(\"ms\"),\n",
    "        col(\"t.movieId\") == col(\"ms.movieId_test\"),  # Связываем фильмы из тестового множества с похожими\n",
    "        \"left\"\n",
    "    )\n",
    "    .join(\n",
    "        train_init.alias(\"tr\"),\n",
    "        col(\"ms.movieId_train\") == col(\"tr.movieId\"),  # Связываем с рейтингами соседей\n",
    "        \"left\"\n",
    "    )\n",
    "    .groupBy(\"t.userId\", \"t.movieId\")\n",
    "    .agg(\n",
    "        spark_sum(col(\"ms.similarity\") * col(\"tr.rating\")).alias(\"weighted_sum\"),\n",
    "        spark_sum(col(\"ms.similarity\")).alias(\"similarity_sum\"),\n",
    "    )\n",
    "    .withColumn(\"prediction\", col(\"weighted_sum\") / col(\"similarity_sum\"))\n",
    "    .select(\"userId\", \"movieId\", \"prediction\")\n",
    ")\n",
    "\n",
    "# 4. Оценка качества модели (RMSE)\n",
    "# Объединяем предсказания с реальными рейтингами\n",
    "test_with_predictions = test.join(predictions, [\"userId\", \"movieId\"], \"left\")\n",
    "\n",
    "# Заполняем пропущенные значения средним рейтингом (если фильм не имеет похожих)\n",
    "test_with_predictions = test_with_predictions.fillna(mean_rating, subset=[\"prediction\"])\n",
    "\n",
    "# Вычисление RMSE\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse_collaborative = evaluator.evaluate(test_with_predictions)\n",
    "\n",
    "print(f\"RMSE для коллаборативной фильтрации: {rmse_collaborative:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c8684c-cfbe-4ecf-b602-3a768dcaaa13",
   "metadata": {},
   "source": [
    "Для расчетов не хватает пространства на диске, больше выделить физически не могу :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2bc67ed-e851-49bd-8568-5cc7c2c54077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Остановка SparkSession\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3a7be5-ab48-4815-b6c8-f95d029a8070",
   "metadata": {},
   "source": [
    "**Задание 3. Факторизация матрицы**\n",
    "1. Выберите модель ALS по минимальному значению rmse. Для этого используйте кросс-валидацию k-folds c k=4\n",
    "\n",
    "Параметры:\n",
    "\n",
    "Количество факторов: [5, 10, 15]\n",
    "\n",
    "Регуляризация: [0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "⚠️ Замечание: Если какие-то элементы из тестового/валидационного подмножества не встречались в обучающем, то rmse будет NaN\n",
    "\n",
    "2. Сравните результаты рекомендаций посредством коллаборативной фильтрации и факторизации матрицы рейтингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1edf7d53-e8e8-4bb2-ba49-953c275a1298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o9309.collectToPython.\n: java.lang.OutOfMemoryError: Java heap space\n\tat scala.collection.mutable.ResizableArray.ensureSize(ResizableArray.scala:106)\n\tat scala.collection.mutable.ResizableArray.ensureSize$(ResizableArray.scala:96)\n\tat scala.collection.mutable.ArrayBuffer.ensureSize(ArrayBuffer.scala:49)\n\tat scala.collection.mutable.ArrayBuffer.$plus$eq(ArrayBuffer.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeCollect$2(SparkPlan.scala:449)\n\tat org.apache.spark.sql.execution.SparkPlan$$Lambda$3541/833111582.apply(Unknown Source)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.util.NextIterator.foreach(NextIterator.scala:21)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeCollect$1(SparkPlan.scala:449)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeCollect$1$adapted(SparkPlan.scala:448)\n\tat org.apache.spark.sql.execution.SparkPlan$$Lambda$3540/1478847382.apply(Unknown Source)\n\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:448)\n\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:4149)\n\tat org.apache.spark.sql.Dataset$$Lambda$4049/946361721.apply(Unknown Source)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4323)\n\tat org.apache.spark.sql.Dataset$$Lambda$2021/472450626.apply(Unknown Source)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4321)\n\tat org.apache.spark.sql.Dataset$$Lambda$1673/156838736.apply(Unknown Source)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$$$Lambda$1684/1386522056.apply(Unknown Source)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.execution.SQLExecution$$$Lambda$1674/1690301035.apply(Unknown Source)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4321)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:4146)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 41\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k_folds):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# Определяем обучающую и валидационную выборки\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     validation \u001b[38;5;241m=\u001b[39m folds[i]\n\u001b[1;32m     40\u001b[0m     train \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mcreateDataFrame(\n\u001b[0;32m---> 41\u001b[0m         [row \u001b[38;5;28;01mfor\u001b[39;00m j, fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(folds) \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;241m!=\u001b[39m i \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m fold\u001b[38;5;241m.\u001b[39mcollect()]\n\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# Инициализация модели ALS\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     als \u001b[38;5;241m=\u001b[39m ALS(\n\u001b[1;32m     46\u001b[0m         maxIter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     47\u001b[0m         rank\u001b[38;5;241m=\u001b[39mfactor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m         seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[1;32m     54\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[31], line 41\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k_folds):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# Определяем обучающую и валидационную выборки\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     validation \u001b[38;5;241m=\u001b[39m folds[i]\n\u001b[1;32m     40\u001b[0m     train \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mcreateDataFrame(\n\u001b[0;32m---> 41\u001b[0m         [row \u001b[38;5;28;01mfor\u001b[39;00m j, fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(folds) \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;241m!=\u001b[39m i \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfold\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# Инициализация модели ALS\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     als \u001b[38;5;241m=\u001b[39m ALS(\n\u001b[1;32m     46\u001b[0m         maxIter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     47\u001b[0m         rank\u001b[38;5;241m=\u001b[39mfactor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m         seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[1;32m     54\u001b[0m     )\n",
      "File \u001b[0;32m~/_practice/spark-3.5.4-bin-hadoop3/python/pyspark/sql/dataframe.py:1263\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m \n\u001b[1;32m   1245\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1260\u001b[0m \u001b[38;5;124;03m[Row(age=14, name='Tom'), Row(age=23, name='Alice'), Row(age=16, name='Bob')]\u001b[39;00m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc):\n\u001b[0;32m-> 1263\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectToPython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[0;32m~/_practice/spark-3.5.4-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/_practice/spark-3.5.4-bin-hadoop3/python/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/_practice/spark-3.5.4-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o9309.collectToPython.\n: java.lang.OutOfMemoryError: Java heap space\n\tat scala.collection.mutable.ResizableArray.ensureSize(ResizableArray.scala:106)\n\tat scala.collection.mutable.ResizableArray.ensureSize$(ResizableArray.scala:96)\n\tat scala.collection.mutable.ArrayBuffer.ensureSize(ArrayBuffer.scala:49)\n\tat scala.collection.mutable.ArrayBuffer.$plus$eq(ArrayBuffer.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeCollect$2(SparkPlan.scala:449)\n\tat org.apache.spark.sql.execution.SparkPlan$$Lambda$3541/833111582.apply(Unknown Source)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.util.NextIterator.foreach(NextIterator.scala:21)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeCollect$1(SparkPlan.scala:449)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeCollect$1$adapted(SparkPlan.scala:448)\n\tat org.apache.spark.sql.execution.SparkPlan$$Lambda$3540/1478847382.apply(Unknown Source)\n\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:448)\n\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:4149)\n\tat org.apache.spark.sql.Dataset$$Lambda$4049/946361721.apply(Unknown Source)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4323)\n\tat org.apache.spark.sql.Dataset$$Lambda$2021/472450626.apply(Unknown Source)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4321)\n\tat org.apache.spark.sql.Dataset$$Lambda$1673/156838736.apply(Unknown Source)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$$$Lambda$1684/1386522056.apply(Unknown Source)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.execution.SQLExecution$$$Lambda$1674/1690301035.apply(Unknown Source)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4321)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:4146)\n"
     ]
    }
   ],
   "source": [
    "# 1. Выберите модель ALS по минимальному значению rmse. Для этого используйте кросс-валидацию k-folds c k=4\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "import numpy as np\n",
    "\n",
    "# Инициализация SparkSession\n",
    "spark = SparkSession.builder.appName(\"Movies3 Marchuk\").getOrCreate()\n",
    "\n",
    "# Загрузка данных\n",
    "ratings = spark.read.csv(\"/dataset/hw4/big/ratings.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Параметры для кросс-валидации\n",
    "k_folds = 4\n",
    "factors = [5, 10, 15]\n",
    "reg_params = [0.001, 0.01, 0.1, 1, 10]\n",
    "seed = 42\n",
    "\n",
    "# Функция для вычисления RMSE\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "# Кросс-валидация\n",
    "min_rmse = float(\"inf\")\n",
    "best_model_params = None\n",
    "\n",
    "# Создаем k фолдов\n",
    "folds = ratings.randomSplit([1.0 / k_folds] * k_folds, seed=seed)\n",
    "\n",
    "for factor in factors:\n",
    "    for reg_param in reg_params:\n",
    "        fold_rmse = []\n",
    "        \n",
    "        for i in range(k_folds):\n",
    "            # Определяем обучающую и валидационную выборки\n",
    "            validation = folds[i]\n",
    "            train = spark.createDataFrame(\n",
    "                [row for j, fold in enumerate(folds) if j != i for row in fold.collect()]\n",
    "            )\n",
    "            \n",
    "            # Инициализация модели ALS\n",
    "            als = ALS(\n",
    "                maxIter=10,\n",
    "                rank=factor,\n",
    "                regParam=reg_param,\n",
    "                userCol=\"userId\",\n",
    "                itemCol=\"movieId\",\n",
    "                ratingCol=\"rating\",\n",
    "                coldStartStrategy=\"drop\",  # Убираем NaN предсказания\n",
    "                seed=seed,\n",
    "            )\n",
    "            \n",
    "            # Обучение модели\n",
    "            model = als.fit(train)\n",
    "            \n",
    "            # Предсказания на валидационном наборе\n",
    "            predictions = model.transform(validation)\n",
    "            \n",
    "            # Вычисление RMSE\n",
    "            rmse = evaluator.evaluate(predictions)\n",
    "            fold_rmse.append(rmse)\n",
    "        \n",
    "        # Среднее RMSE для текущих параметров\n",
    "        avg_rmse = np.mean(fold_rmse)\n",
    "        \n",
    "        print(f\"Factor: {factor}, RegParam: {reg_param}, RMSE: {avg_rmse:.4f}\")\n",
    "        \n",
    "        # Сохранение лучших параметров\n",
    "        if avg_rmse < min_rmse:\n",
    "            min_rmse = avg_rmse\n",
    "            best_model_params = {\"factor\": factor, \"regParam\": reg_param}\n",
    "\n",
    "print(f\"\\nЛучшие параметры: {best_model_params}\")\n",
    "print(f\"Минимальное RMSE: {min_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeb804a-acde-44ca-bf29-622463ff67ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "То же самое, не хватает места("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7e4cf79-552a-459a-8212-99d6bf225c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Остановка SparkSession\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1b90f7-d4ff-4b5f-8863-8562ae9b5bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
